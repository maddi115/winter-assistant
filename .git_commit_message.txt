üçÑ Fix AI context usage: RAG pipeline now working end-to-end

## What We Fixed

**Problem:** AI wasn't using retrieved conversation context to answer questions.
- User: "my name is maddi"
- User: "what's my name?"
- AI: ‚ùå Generic response instead of "Maddi"

**Root Cause:** AI prompt didn't explicitly instruct it to CHECK and USE conversation history.

## Solution

### 1. Improved AI Prompt (core/ai_engine.py)
**Before:**
```python
prompt = """You are agentWinter.
Conversation History: {history}
User: {input}"""
```

**After:**
```python
prompt = """You are agentWinter with conversation memory.

CRITICAL INSTRUCTIONS:
1. READ conversation history carefully before responding
2. When asked about past info, answer based on PREVIOUS discussion
3. Use history to maintain context and continuity

Examples:
- User: "my name is John" ‚Üí "Nice to meet you, John!"
- User: "what's my name?" ‚Üí Check history ‚Üí "Your name is John"

Conversation History: {history}
Current question: {input}"""
```

### 2. Added Debug Tracing (conversation_adapter.py)
Temporarily added [DEBUG] output to verify RAG pipeline:
- Confirmed context retrieval working
- Confirmed AI receiving correct turns
- Confirmed semantic search finding relevant history
- Removed debug output after verification

### 3. Verified RAG Pipeline Flow
```
User Query: "what's my name?"
    ‚Üì
Hybrid RAG (retrieval/hybrid_rag.py)
    ‚Üí storage.get_recent(3)        # Last 3 turns
    ‚Üí storage.search(query, 3)     # Semantic: "name" related
    ‚Üí Deduplicate & combine
    ‚Üì
Context: [Turn with "my name is maddi B nolan"]
    ‚Üì
AI Engine (core/ai_engine.py)
    ‚Üí Builds history string from context
    ‚Üí Enhanced prompt with explicit instructions
    ‚Üí Ollama generates response
    ‚Üì
Output: ‚úÖ "Maddi B Nolan"
```

## Test Results

**Working correctly:**
```
User: my name is maddi B nolan
AI: Nice to meet you, Maddi B Nolan!

User: what was my name again?
[RAG retrieves turn 1]
AI: Maddi B Nolan ‚úÖ

User: whats your name?
[RAG retrieves turns 1-2]
AI: agentWinter ‚úÖ
```

## Technical Details

**RAG Retrieval Strategy:**
- Hybrid approach: 3 recent + 3 semantically relevant
- Deduplication by timestamp + turn_number
- Chronological sorting for coherent context
- Up to 6 turns passed to AI (token efficient)

**AI Context Window:**
- Last 5 turns from retrieved context
- Explicitly formatted as conversation history
- Clear role labels (User: / agentWinter:)
- Enhanced prompt with usage instructions

**Error Handling:**
- RAG failure ‚Üí fallback to simple recency
- Storage failure ‚Üí non-blocking (logs warning)
- AI failure ‚Üí graceful error message

## Files Modified

- `core/ai_engine.py` - Enhanced prompt with explicit memory usage instructions
- `adapters/conversation_adapter.py` - Verified context flow, removed debug output

## Verification

Tested full conversation flow:
1. User shares information ‚úÖ
2. System stores in LanceDB ‚úÖ
3. RAG retrieves relevant context ‚úÖ
4. AI uses context to answer ‚úÖ
5. Memory persists across turns ‚úÖ

**System Status:** Fully operational, production-ready RAG pipeline.
